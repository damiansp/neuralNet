{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "democratic-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from   torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from   torch.utils.data import DataLoader, TensorDataset\n",
    "from   torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "digital-socket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0625, -0.0360,  0.0428, -0.0627],\n",
       "        [ 0.0290, -0.0901,  0.0452,  0.0170],\n",
       "        [-0.0469,  0.0030, -0.0849,  0.0567],\n",
       "        ...,\n",
       "        [-0.0629,  0.0163,  0.0182, -0.0351],\n",
       "        [-0.1026,  0.0437,  0.1005,  0.0608],\n",
       "        [ 0.0586, -0.0132,  0.0254, -0.0386]], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn(256, 4) / math.sqrt(256)\n",
    "W.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prescription-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.zeros(4, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "removed-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy\n",
    "# loss = loss_func(mod(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "characteristic-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = optim.SGD(mod.parameter(), lr=ETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "running-seating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nopt.step()\\nopt.zero_grad()\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "with torch.no_grad():\n",
    "    for param in mod.parameters:\n",
    "        param -= param.grad * ETA # grad desc step\n",
    "    mod.zero_grad()\n",
    "'''\n",
    "\n",
    "# Equivalent to:\n",
    "'''\n",
    "opt.step()\n",
    "opt.zero_grad()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "israeli-heaven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor X_batch, y_batch in train_dataloader:\\n    preds = mod(X_batch)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batc_size=BATCH)\n",
    "'''\n",
    "\n",
    "# now instead of manually iterating through data like:\n",
    "'''\n",
    "for i in range((n - 1) // bs + 1):\n",
    "    X_batch = X_train[start:end]\n",
    "    y_batch = y_train[start:end]\n",
    "    preds = mod(X_batch)\n",
    "'''\n",
    "\n",
    "# ...can simplify to\n",
    "'''\n",
    "for X_batch, y_batch in train_dataloader:\n",
    "    preds = mod(X_batch)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "signed-shadow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([1., 4., 2., 1., 3., 5.])\n",
    "points[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "median-seating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "orange-stations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "located-limit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0\n",
       " 4.0\n",
       " 2.0\n",
       " 1.0\n",
       " 3.0\n",
       " 5.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[1., 4.], [2., 1.], [3., 5.]])\n",
    "points.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "approved-nudist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape, points.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "superior-floor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.storage_offset() # index of 1st elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "binary-garbage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1].storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "coated-capability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "suburban-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.tensor([[1., 2.], [3., 4.]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "defensive-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.tensor(\n",
    "    [[1., 2.], [3., 4.]], dtype=torch.float32, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "irish-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "#points2 = points.to(device='cuda')\n",
    "#points3 = points.to(device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "american-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN for MNIST\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cn1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.cn2 = nn.Conv2d(16, 32, 3, 1)\n",
    "        self.dp1 = nn.Dropout2d(0.1)\n",
    "        self.dp2 = nn.Dropout2d(0.25)\n",
    "        self.fc1 = nn.Linear(12 * 12 * 32, 64)\n",
    "        self.fc2 = nn.Lenear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.cn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dp1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp2(x)\n",
    "        x = self.fc2(x)\n",
    "        op = F.log_softmax(x, dim=1)\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "covered-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mod, device, train_dataloader, optim, epoch):\n",
    "    mod.train()\n",
    "    for i, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optim.zero_grad()\n",
    "        pred_prob = mod(X)\n",
    "        loss = F.nll_(pred_prob, y) # negative log likelihood\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if i % 10 == 0:\n",
    "            print(f'epoch: {epoch} '\n",
    "                  f'[{i * len(X)}/{len(train_dataloader.dataset)} '\n",
    "                  f'({100. * i / len(train_dataloader)::.2f}%)]\\t'\n",
    "                  f'training loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "exciting-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(mod, device, test_dataloader):\n",
    "    mod.eval()\n",
    "    loss = 0\n",
    "    success = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred_prob = mod(X)\n",
    "            loss += F.nll_loss(pred_prob, y, reduction='sum').items()\n",
    "            pred = pred_prob.argmax(dim=1, keepdim=True)\n",
    "            success += pred.eq(y.view_as(pred)).sum().item()\n",
    "    n = len(test_dataloader.dataset)\n",
    "    loss /= n\n",
    "    print(f'\\nTest dataset: Overall loss: {loss:.4f}, Overall Accuracy: '\n",
    "          f'{success}/{n} ({100*success / n:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "sharing-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = '../../../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "daily-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORM_MEAN = 0.1302 # train_X.mean() / 256.\n",
    "NORM_SD = 0.3069 # train_X.std() / 256.\n",
    "BATCH = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "refined-correction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43b5d87341a4c23a589a6a4243737d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b28725abd2848349eab1c5318b581e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a2681687ba40f4a9e74a022894a71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd2dd028aed4787b8958808fcacdf59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../../data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    datasets.MNIST(\n",
    "        DATA, \n",
    "        train=True, \n",
    "        download=True, \n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize((NORM_MEAN,), (NORM_SD,))])\n",
    "    ),\n",
    "    batch_size = BATCH,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "suspected-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    datasets.MNIST(\n",
    "        DATA, \n",
    "        train=False, \n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize((NORM_MEAN,), (NORM_SD,))])), \n",
    "    batch_size=500, \n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-rally",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
